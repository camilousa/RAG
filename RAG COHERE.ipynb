{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42f1952-8bdf-42d4-b40f-ed1f703ddeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "%pip install -qU \"langchain[cohere]\" langchain-postgres\n",
    "%pip install -qU boto3 pypdf\n",
    "%pip install -qU langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c869503e-2125-4845-a9a4-343cdd78482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import tempfile\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import getpass\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea2b8b-3ea7-479f-bc4f-3dfdbc6d27c1",
   "metadata": {},
   "source": [
    "# Configuraci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d19f16-c2b8-40c7-ae3d-928a3e287eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LangSmith API Key:  路路路路路路路路\n",
      "Enter API key for Cohere:  路路路路路路路路\n",
      "PostgreSQL URI (postgresql+psycopg://...):  路路路路路路路路\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter API key for Cohere: \")\n",
    "POSTGRES_URI = getpass.getpass(\"PostgreSQL URI (postgresql+psycopg://...): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d49ce1-31f5-4804-9813-4976bd4d6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"command-r-plus\", model_provider=\"cohere\")\n",
    "embeddings = CohereEmbeddings(model=\"embed-multilingual-v3.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90f6082-01cf-49c5-a725-e8ee34bfcf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"docs_cohere\",\n",
    "    connection=POSTGRES_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9744f-ea6c-41bf-837a-c48cfc673713",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1874f7-1ca7-4b62-937c-a7de70b9835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargados 27 documentos PDF desde S3.\n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"docsragusa\"\n",
    "prefix = \"\" \n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "for obj in response.get(\"Contents\", []):\n",
    "    key = obj[\"Key\"]\n",
    "    if key.endswith(\".pdf\"):\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as tmp:\n",
    "            s3.download_fileobj(bucket_name, key, tmp)\n",
    "            tmp.flush()\n",
    "            loader = PyPDFLoader(tmp.name)\n",
    "            docs = loader.load()\n",
    "            all_docs.extend(docs)\n",
    "\n",
    "print(f\"Cargados {len(all_docs)} documentos PDF desde S3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0a80e98-ed09-4fc4-a8bd-02688832027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f782fe95-020d-4858-8d60-9bdf1b9d5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = vector_store.add_documents(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e178f-f6d9-493c-b96e-97bf317b71f9",
   "metadata": {},
   "source": [
    "# Recuperaci贸n de informaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c39e35f8-c7ff-44d7-bc68-cc00b7ec7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \n",
    "                              \"context\": docs_content,\n",
    "                              \"instruction\": \"Por favor responde en espa帽ol de forma clara y precisa.\"\n",
    "                            })\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f52d1cf7-2865-4a06-bf29-4860c97afc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Por favor escribe tu pregunta (o 'salir' para terminar):  驴quien escribio el cuadernillo?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BOT: \n",
      "Pilar Gaspar, Silvia Gonzalez, Mariela Helman y Ravia Zuberman escribieron el cuadernillo.\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Por favor escribe tu pregunta (o 'salir' para terminar):  salir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 隆Gracias por usar el chat! Hasta luego.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_question = input(\" Por favor escribe tu pregunta (o 'salir' para terminar): \")\n",
    "    if user_question.lower() in (\"salir\", \"exit\", \"quit\"):\n",
    "        print(\" 隆Gracias por usar el chat! Hasta luego.\")\n",
    "        break\n",
    "    response = graph.invoke({\"question\": user_question})\n",
    "    print(\"\\nBOT: \")\n",
    "    print(response[\"answer\"])\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
